# ğŸŒŸ C++ Code to Pseudocode Generator | Transformer from Scratch

This project features a **Transformer-based Sequence-to-Sequence (Seq2Seq) model** that translates **C++ code â pseudocode**. Built entirely from scratch in **PyTorch**, this project does not use pretrained models and provides an in-depth educational example of a Transformer model.

The model has been deployed with an interactive **Streamlit** web app, allowing users to generate pseudocode from C++ code easily.

---

## ğŸ“Œ Key Features

- ğŸ”¹ **Transformer-based Model**: Built from scratch using `torch.nn.Transformer` for C++ to pseudocode translation.
- ğŸ”¹ **Custom Tokenizer**: Handles tokenization of C++ code and pseudocode with special tokens like `<sos>`, `<eos>`, and `<pad>`.
- ğŸ”¹ **Interactive Streamlit Web App**: Allows users to input C++ code and generate corresponding pseudocode in real time.
- ğŸ”¹ **Cleaned Dataset**: Trained on a customized SPOC dataset, preprocessed to handle missing or misaligned pseudocode entries.

---

## ğŸš€ Demo

Try it out yourself:

ğŸ”— **Live Streamlit App**: *[Streamlit link here](https://xc2vptrxpbfryq3axfuuax.streamlit.app/)*  

---

## ğŸ§  Concepts Used

### âœ¨ Transformer (Seq2Seq) â€“ From Scratch
- Encoder-Decoder architecture using `torch.nn.Transformer`
- **Positional Encoding** to retain sequence order
- **Multi-head attention** and **feed-forward layers** for processing complex code relationships
- **Greedy decoding loop** for generating output

### âœ¨ Tokenization
- Custom word-level tokenizer
- Special tokens handling: `<sos>`, `<eos>`, `<pad>`, `<unk>`
  
### âœ¨ Dataset
- **SPOC Dataset**: A curated dataset containing C++ code and corresponding pseudocode pairs.
- **Preprocessing**: Missing or misaligned pseudocode and code were realigned to ensure the quality of training data.

---

## ğŸ§ª Model Architecture
    [C++ Code] 
       â†“ 
    Tokenization + <sos>/<eos> 
       â†“
    Embedding + Positional Encoding
       â†“
    Transformer Encoder-Decoder
       â†“
    Linear Layer + Softmax 
       â†“
    [Generated Pseudocode]

